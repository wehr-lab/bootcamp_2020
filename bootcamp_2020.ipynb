{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootcamp 2020\n",
    "\n",
    "In the last part of today I will\n",
    "\n",
    "* introduce you to Python\n",
    "* introduce you to some basic ideas about analyzing aggregates of neurons\n",
    "* give some tips on cultivating your beautiful life in data\n",
    "\n",
    "We don't have time today to give a good programming lesson, so forgive me for lack of detail on specifics of Python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, in Python we explicitly \"import\" other code that we want to use from \"packages\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RendererRegistry.enable('notebook')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob # wildcard file selection\n",
    "from pprint import pprint # pretty printing\n",
    "\n",
    "# load the dreaded matplotlib\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd      # data structures\n",
    "import numpy as np       # basic numerical operations\n",
    "import altair as alt     # plotting library\n",
    "from scipy.io import wavfile # loading sound files\n",
    "from scipy import signal # for making spectograms\n",
    "from ipywidgets import interact, fixed # buttons and stuff\n",
    "# with respect to https://github.com/Chekos/blog-posts/tree/master/altair%20%2B%20ipywidgets\n",
    "\n",
    "\n",
    "# tell plotting library not to try and hold everything in memory\n",
    "alt.data_transformers.enable('json')\n",
    "# and let it render good\n",
    "alt.renderers.enable('notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Load Data!\n",
    "\n",
    "I've already taken the data output from the recording and cleaned it up into \"long\" format -- more on that later -- using the `clean_out_dir.m` MATLAB code found in the repository\n",
    "\n",
    "Now find and load it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search string: /Users/jonny/git/bootcamp_2020/data/tones/*.csv\n",
      "          \n",
      "Globbed Filenames: ['/Users/jonny/git/bootcamp_2020/data/tones/2020-09-03_17-41-32_tones.csv']\n"
     ]
    }
   ],
   "source": [
    "# start with tuning curves -- \n",
    "# build a string with a wildcard * to search for files we want\n",
    "tc_search = os.path.join(os.getcwd(),'data','tones', \"*.csv\")\n",
    "\n",
    "# use glob to find the files!\n",
    "tc_fns = glob(tc_search)\n",
    "\n",
    "#what did we get?\n",
    "print(f\"\"\"\\nSearch string: {tc_search}\n",
    "          \\nGlobbed Filenames: {tc_fns}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll load the file and see what inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amps</th>\n",
       "      <th>cell</th>\n",
       "      <th>dur</th>\n",
       "      <th>expt</th>\n",
       "      <th>freqs</th>\n",
       "      <th>rep</th>\n",
       "      <th>spikes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>4000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.566667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>5656.85</td>\n",
       "      <td>1</td>\n",
       "      <td>21.633333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>11313.70</td>\n",
       "      <td>1</td>\n",
       "      <td>26.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>11313.70</td>\n",
       "      <td>1</td>\n",
       "      <td>36.366667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>22627.40</td>\n",
       "      <td>1</td>\n",
       "      <td>16.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>1000.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.433333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>1414.21</td>\n",
       "      <td>1</td>\n",
       "      <td>21.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>1414.21</td>\n",
       "      <td>1</td>\n",
       "      <td>29.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>22627.40</td>\n",
       "      <td>1</td>\n",
       "      <td>22.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>tuning_curve</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9.766667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amps  cell  dur          expt     freqs  rep     spikes\n",
       "0    40     1   25  tuning_curve   4000.00    1   1.566667\n",
       "1    40     1   25  tuning_curve   5656.85    1  21.633333\n",
       "2    40     1   25  tuning_curve  11313.70    1  26.866667\n",
       "3    40     1   25  tuning_curve  11313.70    1  36.366667\n",
       "4    40     1   25  tuning_curve  22627.40    1  16.666667\n",
       "5    55     1   25  tuning_curve   1000.00    1   1.433333\n",
       "6    55     1   25  tuning_curve   1414.21    1  21.333333\n",
       "7    55     1   25  tuning_curve   1414.21    1  29.100000\n",
       "8    55     1   25  tuning_curve  22627.40    1  22.300000\n",
       "9    70     1   25  tuning_curve     -1.00    1   9.766667"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if len(tc_fns) == 1:\n",
    "    # make a pandas dataframe out of our .csv file\n",
    "    df = pd.read_csv(tc_fns[0])\n",
    "    \n",
    "# print the first n rows (default 5, try giving another number as an argument)\n",
    "#df.head()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data is in a format where every **row** is a single spike and every **column** is a variable that describes the spike. In this case we have\n",
    "\n",
    "* **expt** - some short description of the type of experiment that was run\n",
    "* **cell** - the cell that the spike came from\n",
    "* **rep** - the repetition of the tone that was presented\n",
    "* **freqs** - the frequency of the presented tone\n",
    "* **amps** - the amplitude of the presented tone in dBSPL\n",
    "* **dur** - the duration of the presented tone\n",
    "* **spikes** - the time of the spike in ms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our data is in a computable format, we don't need special custom code to do simple analysis and description of it. Data has a long lifetime -- it goes through many forms, is combined with data of different types, etc -- so being purposive when deciding the format we want to store and operate on our data is extremely important to staying sane in analysis. Again more on this later\n",
    "\n",
    "A very simple summary we can do is count the number of unique cells in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 unique cells: [1 7]\n"
     ]
    }
   ],
   "source": [
    "# here we are using python f-string formatting. by putting f before the string,\n",
    "# we can interpolate our variables inside of {}s\n",
    "\n",
    "unique_cells = df['cell'].unique()\n",
    "n_unique_cells = len(unique_cells)\n",
    "\n",
    "print(f\"There are {n_unique_cells} unique cells: {unique_cells}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same thing for frequencies and amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequencies:\n",
      "\n",
      "array([ 4.00000e+03,  5.65685e+03,  1.13137e+04,  2.26274e+04,\n",
      "        1.00000e+03,  1.41421e+03, -1.00000e+00,  2.82843e+03,\n",
      "        1.60000e+04,  6.40000e+04,  2.00000e+03,  8.00000e+03,\n",
      "        3.20000e+04,  4.52548e+04])\n",
      "\n",
      "\n",
      "Amplitudes:\n",
      "\n",
      "array([40, 55, 70])\n"
     ]
    }
   ],
   "source": [
    "uq_freqs = df['freqs'].unique()\n",
    "uq_amps  = df['amps'].unique()\n",
    "\n",
    "print('Frequencies:\\n')\n",
    "pprint(uq_freqs)\n",
    "print('\\n\\nAmplitudes:\\n')\n",
    "pprint(uq_amps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Spike Raster\n",
    "\n",
    "We make a classic raster first.\n",
    "\n",
    "I am trying out a new plotting library, [Altair](https://altair-viz.github.io), so refer to its documentation :)\n",
    "\n",
    "First we're going to make a **function** to make the plot -- making a function lets us encapsulate all the logic of an operation we want to do (like plot a spike raster) so we don't have to write it all every time. You don't need to understand the code that goes inside of the  function for now, as it is mostly idiosyncratic to the altair library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_raster(cell: int, data: pd.DataFrame) -> alt.Chart:\n",
    "    \"\"\"\n",
    "    Plot a spike raster plot for a single cell\n",
    "    \n",
    "    Args:\n",
    "        cell (int): The ID of the cell to plot\n",
    "        data: (pandas.DataFrame): DataFrame object containing data\n",
    "        \n",
    "    Returns:\n",
    "        altair.Chart: The created chart\n",
    "    \"\"\"\n",
    "    \n",
    "    # we first declare a Chart object, subsetting our data to a single cell\n",
    "    # we then mark_circles with the encoding (map from data to graphics)\n",
    "        \n",
    "    chart = alt.Chart(data[data['cell'] == cell]).mark_circle().encode(\n",
    "        x = alt.X('spikes'),      # X axis will be spike time\n",
    "        y = alt.Y('rep' ),        # Y is the stimulus repetition\n",
    "        size = alt.value(5),      # make the dots small\n",
    "        opacity=alt.value(1.),    # opaque\n",
    "        color=alt.condition(      # and...\n",
    "            # if the spike happened during the stimulus presentation\n",
    "            (alt.datum.spikes >= 0) & (alt.datum.spikes<=alt.datum.dur), \n",
    "            alt.value('red'),     # colored red\n",
    "            alt.value('black')    # otherwise black\n",
    "        )\n",
    "    ).properties(\n",
    "        width = 200,\n",
    "        height = 30,\n",
    "    ).facet(\n",
    "        row='freqs',  # split the plot into rows by frequency\n",
    "        column='amps' # and columns by amplitude\n",
    "    )\n",
    "    \n",
    "    return chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use our function, we call it with `()`, putting our arguments within"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const spec = {\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"url\": \"altair-data-6e9fbc3f891c06865396b66500a3758a.json\", \"format\": {\"type\": \"json\"}}, \"mark\": \"circle\", \"encoding\": {\"color\": {\"condition\": {\"value\": \"red\", \"test\": \"((datum.spikes >= 0) && (datum.spikes <= datum.dur))\"}, \"value\": \"black\"}, \"opacity\": {\"value\": 1.0}, \"size\": {\"value\": 5}, \"x\": {\"type\": \"quantitative\", \"field\": \"spikes\"}, \"y\": {\"type\": \"quantitative\", \"field\": \"rep\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.8.1.json\"};\n",
       "const opt = {};\n",
       "const type = \"vega-lite\";\n",
       "const id = \"57a27f67-49e4-496b-9d07-a67846fdb971\";\n",
       "\n",
       "const output_area = this;\n",
       "\n",
       "require([\"nbextensions/jupyter-vega/index\"], function(vega) {\n",
       "  const target = document.createElement(\"div\");\n",
       "  target.id = id;\n",
       "  target.className = \"vega-embed\";\n",
       "\n",
       "  const style = document.createElement(\"style\");\n",
       "  style.textContent = [\n",
       "    \".vega-embed .error p {\",\n",
       "    \"  color: firebrick;\",\n",
       "    \"  font-size: 14px;\",\n",
       "    \"}\",\n",
       "  ].join(\"\\\\n\");\n",
       "\n",
       "  // element is a jQuery wrapped DOM element inside the output area\n",
       "  // see http://ipython.readthedocs.io/en/stable/api/generated/\\\n",
       "  // IPython.display.html#IPython.display.Javascript.__init__\n",
       "  element[0].appendChild(target);\n",
       "  element[0].appendChild(style);\n",
       "\n",
       "  vega.render(\"#\" + id, spec, type, opt, output_area);\n",
       "}, function (err) {\n",
       "  if (err.requireType !== \"scripterror\") {\n",
       "    throw(err);\n",
       "  }\n",
       "});\n"
      ],
      "text/plain": [
       "<vega.vegalite.VegaLite at 0x13a6bd550>"
      ]
     },
     "metadata": {
      "jupyter-vega": "#57a27f67-49e4-496b-9d07-a67846fdb971"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alt.Chart(df[df['cell'] == 1]).mark_circle().encode(\n",
    "        x = alt.X('spikes'),      # X axis will be spike time\n",
    "        y = alt.Y('rep' ),        # Y is the stimulus repetition\n",
    "        size = alt.value(5),      # make the dots small\n",
    "        opacity=alt.value(1.),    # opaque\n",
    "        color=alt.condition(      # and...\n",
    "            # if the spike happened during the stimulus presentation\n",
    "            (alt.datum.spikes >= 0) & (alt.datum.spikes<=alt.datum.dur), \n",
    "            alt.value('red'),     # colored red\n",
    "            alt.value('black')    # otherwise black\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = spike_raster(cell = unique_cells[0], data = df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dccc17c29c4fa7b9ae82d850f56683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='cell', options=(1, 7), value=1), Output()), _dom_classes=('widget-â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interact(spike_raster,cell = sorted(df['cell'].unique()), data=fixed(df));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beauty in Analysis\n",
    "\n",
    "You probably didn't sign up to be a programmer, but surprise! all neuroscientists have to be programmers. You can think of your data analysis code as being a beautiful garden you can cultivate to get more comfortable, powerful, and easy to use over time by being conscious about best principles, or you can hate and fear it, struggle with it by constantly trying to do the minimum possible programming, and have it be just as frustrating every time you return to it.\n",
    "\n",
    "* data format\n",
    "    * long,\n",
    "    * annotated - documentation *in* the data\n",
    "    * documented - documentation *about* how the data is structured\n",
    "    * indexible - be able to find your data and trust how it is stored.\n",
    "* code structure - write in small chunks.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
